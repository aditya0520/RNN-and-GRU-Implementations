{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mA9qZoIDcx-h"
      },
      "outputs": [],
      "source": [
        "# %pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONgAWhqdoYy-"
      },
      "source": [
        "\n",
        "This may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SS7a7xeEoaV9"
      },
      "outputs": [],
      "source": [
        "# !pip install torchsummaryx==1.1.0\n",
        "# !pip install wandb --quiet\n",
        "# !pip install python-Levenshtein -q\n",
        "# !git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "# !pip install wget -q\n",
        "# %cd ctcdecode\n",
        "# !pip install . -q\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVONJxCobPc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmLNlXPkRvXV",
        "outputId": "dd8fa182-0d45-40d7-a7d2-5111f1c24615"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (0.13.1+cu117)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (1.13.1+cu117)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchaudio) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "78ZTCIXoof2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c10923-9038-4043-ea6d-6fab9f3d7e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torchnlp.nn import LockedDropout\n",
        "import torchaudio\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3-yJ8tok34"
      },
      "source": [
        "# Kaggle Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AdUelfGhom1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccfe386-cd83-4488-efb3-7ada8335f2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8 -q\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"aaayush1\",\"key\":\"9ad570c944c8b67cf242fb16c7cf3f40\"}') # TODO: Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dSjBwfXeoq4B"
      },
      "outputs": [],
      "source": [
        "# !kaggle competitions download -c hw3p2-785-f24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_ruxWP60LCQA"
      },
      "outputs": [],
      "source": [
        "# '''\n",
        "# This will take a couple minutes, but you should see at least the following:\n",
        "# 11-785-f24-hw3p2  ctcdecode  hw3p2asr-f24.zip  sample_data\n",
        "# '''\n",
        "# !unzip -q hw3p2-785-f24.zip\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9v5ewZDMpYA"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Cp-716IMZRd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ORNHnSFroP0"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "outputs": [],
      "source": [
        "# ARPABET PHONEME MAPPING\n",
        "# DO NOT CHANGE\n",
        "\n",
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict[:-2]\n",
        "LABELS = ARPAbet[:-2]\n",
        "# PHONEMES = sorted(PHONEMES)\n",
        "# LABELS = sorted(LABELS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eN2kcxwXLLBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3576749c-aa57-496e-b18e-0bf1de7da9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[SIL]', 'NG', 'F', 'M', 'AE', 'R', 'UW', 'N', 'IY', 'AW', 'V', 'UH', 'OW', 'AA', 'ER', 'HH', 'Z', 'K', 'CH', 'W', 'EY', 'ZH', 'T', 'EH', 'Y', 'AH', 'B', 'P', 'TH', 'DH', 'AO', 'G', 'L', 'JH', 'OY', 'SH', 'D', 'AY', 'S', 'IH']\n",
            "41\n",
            "[' ', '-', 'G', 'f', 'm', '@', 'r', 'u', 'n', 'i', 'W', 'v', 'U', 'o', 'a', 'R', 'h', 'z', 'k', 'C', 'w', 'e', 'Z', 't', 'E', 'y', 'A', 'b', 'p', 'T', 'D', 'c', 'g', 'l', 'j', 'O', 'S', 'd', 'Y', 's', 'I']\n",
            "41\n"
          ]
        }
      ],
      "source": [
        "# You might want to play around with the mapping as a sanity check here\n",
        "print(PHONEMES)\n",
        "print(len(PHONEMES))\n",
        "print(LABELS)\n",
        "print(len(LABELS))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_dir = os.path.join('/content/11785-f24-hw3p2', 'train-clean-100', \"mfcc\")\n",
        "# TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "\n",
        "# TODO: List files in sefl.mfcc_dir using os.listdir in sorted order\n",
        "mfcc_names          = sorted(os.listdir(mfcc_dir))\n",
        "transcript_dir = os.path.join(\"/content/11785-f24-hw3p2\", \"train-clean-100\", \"transcript\")\n",
        "\n",
        "mfcc_files = sorted(os.listdir(mfcc_dir))\n",
        "transcript_files = sorted(os.listdir(transcript_dir))\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Iterate through mfccs and transcripts\n",
        "mfcc_lengths = []\n",
        "\n",
        "# Iterate through MFCC files\n",
        "for i in range(len(mfcc_names)):\n",
        "    mfcc_path = os.path.join(mfcc_dir, mfcc_names[i])\n",
        "\n",
        "    # Load the MFCC\n",
        "    mfcc = np.load(mfcc_path)\n",
        "\n",
        "    # Append the number of time steps (shape[0]) to the list\n",
        "    mfcc_lengths.append(mfcc.shape[0])\n",
        "\n",
        "    transcript_path = os.path.join(transcript_dir,transcript_files[i])\n",
        "    transcript  = np.load(transcript_path)\n",
        "\n",
        "    print(mfcc.shape)\n",
        "    print(transcript.shape)\n",
        "\n",
        "    if i == 3:\n",
        "      break\n",
        "\n",
        "    # print(transcript)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the mean, min, and max\n",
        "# mean_length = np.mean(mfcc_lengths)\n",
        "# min_length = np.min(mfcc_lengths)\n",
        "# max_length = np.max(mfcc_lengths)\n",
        "\n",
        "# print(mean_length)\n",
        "# print(min_length)\n",
        "# print(max_length)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F5vLj6s0t7T",
        "outputId": "1e20ed95-e70b-43f9-85f9-228607edf453"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1404, 28)\n",
            "(147,)\n",
            "(1590, 28)\n",
            "(196,)\n",
            "(1390, 28)\n",
            "(179,)\n",
            "(1467, 28)\n",
            "(183,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmNBKf4JrLV"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "    #TODO\n",
        "    def __init__(self, root, partition=\"train-clean-100\"):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = os.path.join(root, partition, \"mfcc\")\n",
        "        self.transcript_dir = os.path.join(root, partition, \"transcript\")\n",
        "\n",
        "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
        "        self.transcript_files = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        phoneme_to_index = {phoneme: idx for idx, phoneme in enumerate(PHONEMES)}\n",
        "        index_to_phoneme = {idx: phoneme for idx, phoneme in enumerate(PHONEMES)}\n",
        "\n",
        "        # Now assign them to the class attributes\n",
        "        self.PHONEMES = PHONEMES\n",
        "\n",
        "        #TODO\n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfcc_files)\n",
        "\n",
        "        #TODO\n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "\n",
        "        self.phoneme_to_index = phoneme_to_index\n",
        "        self.index_to_phoneme = index_to_phoneme\n",
        "\n",
        "\n",
        "        #TODO\n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        for i in range(self.length):\n",
        "            mfcc_path = os.path.join(self.mfcc_dir, self.mfcc_files[i])\n",
        "            transcript_path = os.path.join(self.transcript_dir, self.transcript_files[i])\n",
        "            mfcc        = np.load(mfcc_path)\n",
        "\n",
        "            mfcc = mfcc - np.mean(mfcc, axis=0, keepdims=True)\n",
        "            mfcc = mfcc / np.std(mfcc, axis=0, keepdims=True)\n",
        "\n",
        "            transcript  = np.load(transcript_path)[1:-1]\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append([self.phoneme_to_index[i] for i in transcript])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "\n",
        "        mfcc = self.mfccs[ind]\n",
        "\n",
        "        transcript = self.transcripts[ind]\n",
        "        return mfcc, transcript\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        # batch of input mfcc coefficients\n",
        "        batch_mfcc = [item[0] for item in batch] # TODO\n",
        "        # batch of output phonemes\n",
        "        batch_transcript = [torch.tensor(item[1], dtype=torch.long) for item in batch]\n",
        "\n",
        "        lengths_mfcc = [mfcc.shape[0] for mfcc in batch_mfcc]\n",
        "        lengths_transcript = [len(transcript) for transcript in batch_transcript]\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_mfcc_pad = pad_sequence(\n",
        "                [torch.tensor(mfcc, dtype=torch.float32) for mfcc in batch_mfcc],\n",
        "                batch_first=True,\n",
        "                padding_value=0.0\n",
        "            )\n",
        "\n",
        "            # Use a custom padding value (-1) for the transcripts\n",
        "        batch_transcript_pad = pad_sequence(\n",
        "                batch_transcript,\n",
        "                batch_first=True,\n",
        "                padding_value=-1\n",
        "            )\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDrxeHfJw4g"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HrLS1wfVJppA"
      },
      "outputs": [],
      "source": [
        "# Test Dataloader\n",
        "#TODO\n",
        "class AudioDatasetTest(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, root, partition=\"test-clean\"):\n",
        "    '''\n",
        "    Initializes the test dataset.\n",
        "\n",
        "    Args:\n",
        "        root (str): Root directory containing the dataset.\n",
        "        partition (str): Partition of the dataset (e.g., \"test-clean\").\n",
        "    '''\n",
        "\n",
        "    # Load the directory for MFCC files\n",
        "    self.mfcc_dir = os.path.join(root, partition, \"mfcc\")\n",
        "    self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
        "\n",
        "    # Length of the dataset\n",
        "    self.length = len(self.mfcc_files)\n",
        "\n",
        "    # Load and normalize all MFCC features\n",
        "    self.mfccs = []\n",
        "    for i in range(self.length):\n",
        "        mfcc_path = os.path.join(self.mfcc_dir, self.mfcc_files[i])\n",
        "        mfcc = np.load(mfcc_path)\n",
        "\n",
        "        # Normalization\n",
        "        mfcc = (mfcc - np.mean(mfcc, axis=0, keepdims=True)) / np.std(mfcc, axis=0, keepdims=True)\n",
        "        self.mfccs.append(mfcc)\n",
        "\n",
        "  def __len__(self):\n",
        "    ''' Returns the total number of items in the dataset. '''\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    '''\n",
        "    Returns the MFCC coefficients for the given index.\n",
        "\n",
        "    Args:\n",
        "        ind (int): Index of the item.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: MFCC features.\n",
        "    '''\n",
        "    return self.mfccs[ind]\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    '''\n",
        "    Collate function for batching test data.\n",
        "\n",
        "    Args:\n",
        "        batch: List of MFCC features.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Padded mfcc features and lengths of original features.\n",
        "    '''\n",
        "\n",
        "    # Extract features and calculate lengths\n",
        "    batch_mfcc = [torch.tensor(item, dtype=torch.float32) for item in batch]\n",
        "    lengths_mfcc = [mfcc.shape[0] for mfcc in batch_mfcc]\n",
        "\n",
        "    # Pad the mfcc features\n",
        "    batch_mfcc_pad = pad_sequence(\n",
        "        batch_mfcc,\n",
        "        batch_first=True,\n",
        "        padding_value=0.0  # Default padding for MFCCs (silent frame)\n",
        "    )\n",
        "\n",
        "    # Return padded features and lengths\n",
        "    return batch_mfcc_pad, torch.tensor(lengths_mfcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-veYcdL6Fe"
      },
      "source": [
        "### Config - Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "outputs": [],
      "source": [
        "root = \"/content/11785-f24-hw3p2\"\n",
        "\n",
        "# Feel free to add more items here\n",
        "config = {\n",
        "    \"beam_width\" : 2,\n",
        "    \"lr\"         : 2e-3,\n",
        "    \"epochs\"     : 60,\n",
        "    \"batch_size\" : 64  # Increase if your device can handle it\n",
        "}\n",
        "\n",
        "# You may pass this as a parameter to the dataset class above\n",
        "# This will help modularize your implementation\n",
        "transforms = [] # set of tranformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmuPk9J6L8dz"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3_kG0gU2x4hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374dfa39-533d-4971-8365-efeef596e020"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# get me RAMMM!!!!\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4mzoYfTKu14s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea1ce16-89c2-48f7-e07c-8efcc4a8fd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  64\n",
            "Train dataset samples = 28539, batches = 446\n",
            "Val dataset samples = 2703, batches = 43\n",
            "Test dataset samples = 2620, batches = 41\n"
          ]
        }
      ],
      "source": [
        "# Create objects for the dataset class\n",
        "# root, partition=\"test-clean\"):\n",
        "# /content/11785-f24-hw3p2/train-clean-100\n",
        "\n",
        "train_data = AudioDataset(root, partition=\"train-clean-100\") #TODO\n",
        "val_data = AudioDataset(root, partition=\"dev-clean\") # TODO : You can either use the same class with some modifications or make a new one :)\n",
        "test_data = AudioDatasetTest(root, partition=\"test-clean\") #TODO\n",
        "\n",
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=config[\"batch_size\"],  # You can set this based on your preference or system capabilities\n",
        "    shuffle=True,\n",
        "    collate_fn=train_data.collate_fn\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=config[\"batch_size\"],  # You can set this based on your preference or system capabilities\n",
        "    shuffle=False,\n",
        "    collate_fn=val_data.collate_fn\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=config[\"batch_size\"],  # You can set this based on your preference or system capabilities\n",
        "    shuffle=False,\n",
        "    collate_fn=test_data.collate_fn\n",
        ")\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cXMtwyviKaxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78447421-85e9-4a6e-c595-24d9c3325f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1601, 28]) torch.Size([64, 195]) torch.Size([64]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSexxhdfMUzx"
      },
      "source": [
        "# NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLad4pChcuvX"
      },
      "source": [
        "## Basic\n",
        "\n",
        "This is a basic block for understanding, you can skip this and move to pBLSTM one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EQhvHr71GJfq"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# class Network(nn.Module):\n",
        "\n",
        "#     def __init__(self, input_size, out_size):\n",
        "\n",
        "#         super(Network, self).__init__()\n",
        "\n",
        "#         # Adding some sort of embedding layer or feature extractor might help performance.\n",
        "#         # self.embedding = ?\n",
        "\n",
        "#         # TODO : look up the documentation. You might need to pass some additional parameters.\n",
        "#         self.lstm = nn.LSTM(input_size=input_size, hidden_size=256, num_layers=1, batch_first=True)\n",
        "\n",
        "#         self.classification = nn.Linear(in_features=256, out_features=out_size)\n",
        "\n",
        "\n",
        "#         self.logSoftmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "#     def forward(self, x, lx):\n",
        "#         #TODO\n",
        "#         # The forward function takes 2 parameter inputs here. Why?\n",
        "#         # Refer to the handout for hints\n",
        "#         packed_x = nn.utils.rnn.pack_padded_sequence(x, lx, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "#         # Process with LSTM\n",
        "#         # packed_output, _ = self.lstm(packed_x)\n",
        "#         output, _ = self.lstm(x)\n",
        "\n",
        "#         # Unpack the sequence after LSTM\n",
        "#         # output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "#         # Classification and log softmax\n",
        "#         output = self.classification(output)\n",
        "#         output = self.logSoftmax(output)\n",
        "\n",
        "#         return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUThsowyQdN7"
      },
      "source": [
        "## Initialize Basic Network\n",
        "(If trying out the basic Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CGoiXd70tb5z"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# model = Network(input_size=28, out_size=len(PHONEMES)).to(device)\n",
        "# summary(model, x.to(device), lx) # x and lx come from the sanity check above :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-qb7wnAzCZl"
      },
      "source": [
        "## ASR Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet for Embeddings**"
      ],
      "metadata": {
        "id": "qa84HG-aKoSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class IdentityBlock1D(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, filters):\n",
        "#         super(IdentityBlock1D, self).__init__()\n",
        "#         f1, f2 = filters\n",
        "\n",
        "#         self.conv1 = torch.nn.Conv1d(in_channels, f1, kernel_size=3, stride=1, padding=1)\n",
        "#         self.bn1 = torch.nn.BatchNorm1d(f1)\n",
        "\n",
        "#         self.conv2 = torch.nn.Conv1d(f1, f2, kernel_size=3, stride=1, padding=1)\n",
        "#         self.bn2 = torch.nn.BatchNorm1d(f2)\n",
        "\n",
        "#         self.relu = torch.nn.ReLU()\n",
        "\n",
        "#         self.adjust_channels = None\n",
        "#         if in_channels != f2:\n",
        "#             self.adjust_channels = torch.nn.Conv1d(in_channels, f2, kernel_size=1, stride=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "\n",
        "#         # Adjust the channels of `identity` if needed\n",
        "#         if self.adjust_channels is not None:\n",
        "#             identity = self.adjust_channels(identity)\n",
        "\n",
        "#         out += identity\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         return out\n",
        "\n",
        "# class ResNet18(torch.nn.Module):\n",
        "#     def __init__(self, input_dim, embedding_dim):\n",
        "#         super(ResNet18, self).__init__()\n",
        "\n",
        "#         self.conv1 = torch.nn.Conv1d(input_dim, 64, kernel_size=7, stride=1, padding=3)  # Initial layer\n",
        "#         self.bn1 = torch.nn.BatchNorm1d(64)\n",
        "#         self.relu = torch.nn.ReLU()\n",
        "\n",
        "#         # Layer 1\n",
        "#         self.layer1 = torch.nn.Sequential(\n",
        "#             IdentityBlock1D(64, [64, 64]),\n",
        "#             IdentityBlock1D(64, [64, 64])\n",
        "#         )\n",
        "\n",
        "#         # Layer 2\n",
        "#         self.layer2 = torch.nn.Sequential(\n",
        "#             IdentityBlock1D(64, [128, 128]),\n",
        "#             IdentityBlock1D(128, [128, 128])\n",
        "#         )\n",
        "\n",
        "#         # Layer 3\n",
        "#         self.layer3 = torch.nn.Sequential(\n",
        "#             IdentityBlock1D(128, [256, 256]),\n",
        "#             IdentityBlock1D(256, [256, 256])\n",
        "#         )\n",
        "\n",
        "#         # Layer 4\n",
        "#         self.layer4 = torch.nn.Sequential(\n",
        "#             IdentityBlock1D(256, [embedding_dim, embedding_dim]),\n",
        "#             IdentityBlock1D(embedding_dim, [embedding_dim, embedding_dim])\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "4Z7fRr7tKrl4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SeNet for Embeddings\n"
      ],
      "metadata": {
        "id": "EtCfi7-8y1my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock1D(torch.nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock1D, self).__init__()\n",
        "        self.global_avg_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = torch.nn.Linear(channels, channels // reduction, bias=False)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(channels // reduction, channels, bias=False)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, channels, _ = x.size()\n",
        "        # Squeeze\n",
        "        y = self.global_avg_pool(x).view(batch, channels)\n",
        "        y = self.fc1(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.sigmoid(y).view(batch, channels, 1)\n",
        "        # Excitation\n",
        "        return x * y  # Scale the input features\n",
        "\n",
        "class IdentityBlock1D(torch.nn.Module):\n",
        "    def __init__(self, in_channels, filters):\n",
        "        super(IdentityBlock1D, self).__init__()\n",
        "        f1, f2 = filters\n",
        "\n",
        "        self.conv1 = torch.nn.Conv1d(in_channels, f1, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(f1)\n",
        "\n",
        "        self.conv2 = torch.nn.Conv1d(f1, f2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(f2)\n",
        "\n",
        "        self.se_block = SEBlock1D(f2)  # Add SE Block after the second convolution\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        self.adjust_channels = None\n",
        "        if in_channels != f2:\n",
        "            self.adjust_channels = torch.nn.Conv1d(in_channels, f2, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # Apply SE block\n",
        "        out = self.se_block(out)\n",
        "\n",
        "        # Adjust the channels of `identity` if needed\n",
        "        if self.adjust_channels is not None:\n",
        "            identity = self.adjust_channels(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet18(torch.nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        self.conv1 = torch.nn.Conv1d(input_dim, 64, kernel_size=7, stride=1, padding=3)  # Initial layer\n",
        "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        # Layer 1\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            IdentityBlock1D(64, [64, 64]),\n",
        "            IdentityBlock1D(64, [64, 64])\n",
        "        )\n",
        "\n",
        "        # Layer 2\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            IdentityBlock1D(64, [128, 128]),\n",
        "            IdentityBlock1D(128, [128, 128])\n",
        "        )\n",
        "\n",
        "        # Layer 3\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            IdentityBlock1D(128, [256, 256]),\n",
        "            IdentityBlock1D(256, [256, 256])\n",
        "        )\n",
        "\n",
        "        # Layer 4\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            IdentityBlock1D(256, [embedding_dim, embedding_dim]),\n",
        "            IdentityBlock1D(embedding_dim, [embedding_dim, embedding_dim])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5VMVdlmryxAN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6eh3gnMUzy"
      },
      "source": [
        "### Pyramid Bi-LSTM (pBLSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qd4BEX_yMUzz"
      },
      "outputs": [],
      "source": [
        "# Utils for network\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OmdyXI6KMUzz"
      },
      "outputs": [],
      "source": [
        "class pBLSTM(torch.nn.Module):\n",
        "\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
        "\n",
        "    At each step,\n",
        "    1. Pad your input if it is packed (Unpack it)\n",
        "    2. Reduce the input length dimension by concatenating feature dimension\n",
        "        (Tip: Write down the shapes and understand)\n",
        "        (i) How should  you deal with odd/even length input?\n",
        "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
        "    3. Pack your input\n",
        "    4. Pass it into LSTM layer\n",
        "\n",
        "    To make our implementation modular, we pass 1 layer at a time.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(pBLSTM, self).__init__()\n",
        "\n",
        "        self.blstm = nn.LSTM(input_size=input_size,\n",
        "                             hidden_size=hidden_size,\n",
        "                             num_layers=1,\n",
        "                             bidirectional=True,\n",
        "                             batch_first=True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
        "\n",
        "        # TODO: Pad Packed Sequence\n",
        "\n",
        "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
        "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
        "        # TODO: Pack Padded Sequence. What output(s) would you get?\n",
        "        # TODO: Pass the sequence through bLSTM\n",
        "\n",
        "        # What do you return?\n",
        "\n",
        "        x_packed, _ = self.blstm(x_packed)\n",
        "\n",
        "        x, x_lens = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)\n",
        "\n",
        "        x, x_lens = self.trunc_reshape(x, x_lens)\n",
        "\n",
        "        # Step 5: Re-pack the downsampled sequence for the next layer (if any)\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # Return the final packed output\n",
        "        return x_packed\n",
        "\n",
        "    def trunc_reshape(self, x, x_lens):\n",
        "        # TODO: If you have odd number of timesteps, how can you handle it? (Hint: You can exclude them)\n",
        "        # TODO: Reshape x. When reshaping x, you have to reduce number of timesteps by a downsampling factor while increasing number of features by the same factor\n",
        "        # TODO: Reduce lengths by the same downsampling factor\n",
        "        if x.size(1) % 2 != 0:\n",
        "            x = x[:, :-1, :]\n",
        "\n",
        "        # Reshape by concatenating every two time steps\n",
        "        batch_size, seq_len, input_size = x.size()\n",
        "\n",
        "        x = x.view(batch_size, seq_len // 2, input_size * 3)  # New shape: (batch_size, seq_len // 2, input_size * 2)\n",
        "\n",
        "        # Update sequence lengths by dividing by 2\n",
        "        x_lens = x_lens // 2\n",
        "\n",
        "        return x, x_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3ZQ75OcMUz0"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GEzw5_xmMUz0"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            PermuteBlock(),\n",
        "            ResNet18(input_dim=input_size, embedding_dim=encoder_hidden_size),\n",
        "            PermuteBlock()\n",
        "        )\n",
        "\n",
        "        self.pBLSTMs = nn.Sequential(\n",
        "            pBLSTM(input_size=encoder_hidden_size, hidden_size=encoder_hidden_size),\n",
        "            pBLSTM(input_size=encoder_hidden_size * 4, hidden_size=encoder_hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        # TODO: Pack Padded Sequence\n",
        "        # TODO: Pass Sequence through the pyramidal Bi-LSTM layer\n",
        "        # TODO: Pad Packed Sequence\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        x_packed = self.pBLSTMs(x_packed)\n",
        "\n",
        "        encoder_outputs, encoder_lens = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)\n",
        "\n",
        "        return encoder_outputs, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg82HXa3MUz1"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PQIRxdNTMUz1"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, output_size= 41):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            PermuteBlock(),\n",
        "            torch.nn.BatchNorm1d(embed_size),\n",
        "            PermuteBlock(),\n",
        "            torch.nn.Linear(embed_size, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_size)\n",
        "        )\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out):\n",
        "        #TODO call your MLP\n",
        "        #TODO Think what should be the final output of the decoder for the classification\n",
        "        out = self.mlp(encoder_out)\n",
        "\n",
        "        # Apply LogSoftmax for classification probabilities\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qmHf6pFiMUz1"
      },
      "outputs": [],
      "source": [
        "class ASRModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embed_size= 512, output_size= len(PHONEMES)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.augmentations = torch.nn.Sequential(\n",
        "            PermuteBlock(),\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask_param=3),\n",
        "            torchaudio.transforms.TimeMasking(time_mask_param=5),\n",
        "            PermuteBlock()  # Return to original dimension order\n",
        "        )\n",
        "        self.encoder = Encoder(input_size=input_size, encoder_hidden_size=embed_size)\n",
        "        self.decoder = Decoder(embed_size=embed_size * 4, output_size=output_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths_x):\n",
        "\n",
        "        if self.training:\n",
        "            x = self.augmentations(x)\n",
        "\n",
        "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
        "        decoder_out                 = self.decoder(encoder_out)\n",
        "\n",
        "        return decoder_out, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV7DMPDoMUz2"
      },
      "source": [
        "## Initialize ASR Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, lx.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahfSIvCBmfMi",
        "outputId": "8e10d151-6e6b-40a4-e239-98f9a7ab1999"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1601, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oaaDsnnLMUz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45add373-759a-45f9-a27b-56c3ccf432c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASRModel(\n",
            "  (augmentations): Sequential(\n",
            "    (0): PermuteBlock()\n",
            "    (1): FrequencyMasking()\n",
            "    (2): TimeMasking()\n",
            "    (3): PermuteBlock()\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): ResNet18(\n",
            "        (conv1): Conv1d(28, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
            "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU()\n",
            "        (layer1): Sequential(\n",
            "          (0): IdentityBlock1D(\n",
            "            (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "          (1): IdentityBlock1D(\n",
            "            (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): IdentityBlock1D(\n",
            "            (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "            (adjust_channels): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (1): IdentityBlock1D(\n",
            "            (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): IdentityBlock1D(\n",
            "            (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=256, out_features=16, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=16, out_features=256, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "            (adjust_channels): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (1): IdentityBlock1D(\n",
            "            (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=256, out_features=16, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=16, out_features=256, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): IdentityBlock1D(\n",
            "            (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=512, out_features=32, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=32, out_features=512, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "            (adjust_channels): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
            "          )\n",
            "          (1): IdentityBlock1D(\n",
            "            (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "            (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (se_block): SEBlock1D(\n",
            "              (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
            "              (fc1): Linear(in_features=512, out_features=32, bias=False)\n",
            "              (relu): ReLU()\n",
            "              (fc2): Linear(in_features=32, out_features=512, bias=False)\n",
            "              (sigmoid): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): PermuteBlock()\n",
            "    )\n",
            "    (pBLSTMs): Sequential(\n",
            "      (0): pBLSTM(\n",
            "        (blstm): LSTM(512, 512, batch_first=True, bidirectional=True)\n",
            "      )\n",
            "      (1): pBLSTM(\n",
            "        (blstm): LSTM(2048, 512, batch_first=True, bidirectional=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (mlp): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PermuteBlock()\n",
            "      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
            "      (4): ReLU()\n",
            "      (5): Linear(in_features=512, out_features=128, bias=True)\n",
            "      (6): ReLU()\n",
            "      (7): Linear(in_features=128, out_features=41, bias=True)\n",
            "    )\n",
            "    (softmax): LogSoftmax(dim=2)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==============================================================================================================\n",
              "Layer (type:depth-idx)                                       Output Shape              Param #\n",
              "==============================================================================================================\n",
              "ASRModel                                                     [64, 400, 41]             --\n",
              "├─Encoder: 1-1                                               [64, 400, 2048]           --\n",
              "│    └─Sequential: 2-1                                       [64, 1601, 512]           --\n",
              "│    │    └─PermuteBlock: 3-1                                [64, 28, 1601]            --\n",
              "│    │    └─ResNet18: 3-2                                    [64, 512, 1601]           3,946,048\n",
              "│    │    └─PermuteBlock: 3-3                                [64, 1601, 512]           --\n",
              "│    └─Sequential: 2-2                                       [18269, 2048]             --\n",
              "│    │    └─pBLSTM: 3-4                                      [36572, 2048]             4,202,496\n",
              "│    │    └─pBLSTM: 3-5                                      [18269, 2048]             10,493,952\n",
              "├─Decoder: 1-2                                               [64, 400, 41]             --\n",
              "│    └─Sequential: 2-3                                       [64, 400, 41]             --\n",
              "│    │    └─PermuteBlock: 3-6                                [64, 2048, 400]           --\n",
              "│    │    └─BatchNorm1d: 3-7                                 [64, 2048, 400]           4,096\n",
              "│    │    └─PermuteBlock: 3-8                                [64, 400, 2048]           --\n",
              "│    │    └─Linear: 3-9                                      [64, 400, 512]            1,049,088\n",
              "│    │    └─ReLU: 3-10                                       [64, 400, 512]            --\n",
              "│    │    └─Linear: 3-11                                     [64, 400, 128]            65,664\n",
              "│    │    └─ReLU: 3-12                                       [64, 400, 128]            --\n",
              "│    │    └─Linear: 3-13                                     [64, 400, 41]             5,289\n",
              "│    └─LogSoftmax: 2-4                                       [64, 400, 41]             --\n",
              "==============================================================================================================\n",
              "Total params: 19,766,633\n",
              "Trainable params: 19,766,633\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (T): 708.31\n",
              "==============================================================================================================\n",
              "Input size (MB): 11.48\n",
              "Forward/backward pass size (MB): 8593.81\n",
              "Params size (MB): 79.07\n",
              "Estimated Total Size (MB): 8684.35\n",
              "=============================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "model = ASRModel(\n",
        "    input_size  = 28,\n",
        "    embed_size  = 512,\n",
        "    output_size = len(PHONEMES)\n",
        ").to(device)\n",
        "print(model)\n",
        "summary(model, input_data=x.to(device), lengths_x=lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Config\n",
        "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\n",
        "\n",
        "criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
        "# Refer to the handout for hints\n",
        "\n",
        "optimizer =  optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-3)\n",
        "\n",
        "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
        "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "decoder = CTCBeamDecoder(\n",
        "    labels=PHONEMES,\n",
        "    blank_id=0,\n",
        "    beam_width=config[\"beam_width\"],          # Number of beams to consider\n",
        "    num_processes=4,         # Number of parallel processes to speed up decoding\n",
        "    log_probs_input=True     # Whether the input to the decoder is in log probability form\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer,\n",
        "    T_0=4,  # Initial restart period\n",
        "    T_mult=2,     # Multiplicative factor for restart period\n",
        "    eta_min=1e-5\n",
        ")\n",
        "\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmc6_4eWL2Xp"
      },
      "source": [
        "# Decode Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KHjnCDddL36E"
      },
      "outputs": [],
      "source": [
        "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
        "\n",
        "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
        "    beam_results, _, _, out_lens = decoder.decode(output, seq_lens=output_lens) #lengths - list of lengths\n",
        "\n",
        "    pred_strings                    = []\n",
        "\n",
        "    for i in range(output_lens.shape[0]):\n",
        "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
        "        pred_indices = beam_results[i][0][:out_lens[i][0]]\n",
        "        pred_string = ''.join([PHONEME_MAP[idx] for idx in pred_indices])\n",
        "        pred_strings.append(pred_string)\n",
        "\n",
        "    return pred_strings\n",
        "\n",
        "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
        "\n",
        "    dist            = 0\n",
        "    batch_size      = label.shape[0]\n",
        "\n",
        "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # TODO: Get predicted string and label string for each element in the batch\n",
        "        pred_string =  pred_strings[i]\n",
        "        label_indices = label[i][:label_lens[i]]\n",
        "        label_string = ''.join([PHONEME_MAP[idx] for idx in label_indices])\n",
        "        print(\"Pred String is, \", pred_string, \"Label String is:\" ,label_string)\n",
        "        dist += Levenshtein.distance(pred_string, label_string)\n",
        "\n",
        "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
        "    return dist\n",
        "    # return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qk9iZud1LXT"
      },
      "source": [
        "# Test Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GnTLL-5gMBrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b500b61b-2f63-411d-9ca3-f54b8f79e922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 734, 41])\n",
            "torch.Size([734, 64, 41]) torch.Size([64, 265])\n",
            "tensor(7.6832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -mIstRkwIltRIzDApasAlAvDAmIdAlkl@sAzAndwiargl@dtuwElkAmhIzgaspAl-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -ncrIzmIstRkwIltRzm@nRlEsIntrAstIGD@nhIzm@tR-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hitElzAsD@t@tDIsfEstIvsizAnAvDAyIr-wIDkrIsmAsAndrostbiflumIGbIfcrAs-sYmAlzdrcnfrAm-itIGAndItsrIzAlts-AkRmostrEdAlituDAmYnd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hih@zgrevdWtswEDRsRfrEdrIkletAnzwRkIzrIli-grik@ftRcl-Andk@ndIskAvRInItbAtlItAlAv-rakiITAkA-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -lInAlzpIkCRz-arAscrtAv-ApgardzAnd@tEm-pentIGz-AndmesAnzEkskwAzAtYdAlzar@z-n@SAnAl@zAjIGgopoAm-mIstRbRkAtfastRzl@ndskeps-smYl@twAnmACInDAsemweD@tmIstRkarkR-y-yuzdtufl@ShIztiT-AndmIstRjankalyR-gIvzhIzsItR-RACIrfAlsl@panDAb@k-bIfcrhisEzlYkAS@mpuRInAtRkISb@T-nEkstm@n-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -ItIzabviAsli-AnEsAsErifcrAstupOntWthWlumAnAsDizkrItIsIzAmzar-hWd-dElAkAtInIksprESAn-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -anDAjEnRAlprInsApAlzAvartmIstRkwIltRrYtswIDikwAlusIdIti-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -pentIGhitElzAsIz-AvAdIfRAntkwalAtitum@TAm@tIks-AndfInISInartIz-@dIGmcrf@kt-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -@zfcrECIGz-DearAvtukYndz-brItIS-AndfcrAn-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hilAmEntsmostbItRliDAdIvcrsD@th@zbInmedbItwindEkrAtIv-artAnd-dwAtwiyuZAwAlikclpIkCRz-meksDAkAstAmEriApiltuDAl@stjAjmAntAndrimYndzAsD@tInDAgretdezAv-artmYkAl@njAlo-wazDA-fRnISIG-ApolstRr-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -nIrDAfYR-AndDAcrnAmAntsfrEdbrcthomfrAmIndiAanDAm@ntAlbcrd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -Inf@kt-hiIzkwYtsAvIranmIstRrAskIn-fcrnatrikcgnIsIGD@t-ApIkCRSUdInotDAfreltiAvm@n-AndrImarkswIDplizIGkRtAsiAndfIlIsAtAsgresD@t-mEnifezAzAvfilIG-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -onliAnfcrCAnAtlihIzonwRk-nEvRdAzgEt-gUd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -mIstRkwIltRh@zmIsthIzC@ns-fcrhih@zfeldivIntumekhImsElfDAtApRAvpentIG-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -bYhErikwIltR-Em-A-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -bIkczyuwRslipIGInstEdAvkaGkRIG-DAlAvlirozprInsEsh@zbIkAmAfIdAlwITWtAbW-w-wYlpUrS@gisItsDEr-AkuIGdAv-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hih@zgcn-AndgcnfcrgUd-@nsRdpalIkrom-huh@dm@nAjdtuskwizIntuDArumbIsYdDAdr@gAn-Andh@dwItnAstDAkRAnsIzwIDmACIntrAst-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -Yh@vrImendAprIzAnRonlibIkczYwISt-tubiwAn-AndwIDIshistEptfcrwRdAnd-bRstDAstWtCenz@z-izAli@zIfDeh@dbInTrEdz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAlItAlgRlh@dbInAslip-bAtSihRdDAr@psAndopAndDAdcr-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -DAkIGh@zflEdIndIsgresAndycrfrEndzar@skIGfcryu-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -YbEgdrAgEdolcGAgotusEndhImAwebAthiwUdnatduso-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -YclsocfRdtuhElpycrbrADRtuIskep-bAthiwUdnatgo-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hitsAndslipsvEristEdAlirIplYdDAnukIG-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -YhophidAzAntwRktuhard-sEdS@gi-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -hidAzAntwRk@tcl-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -Inf@kt-t-DErIznATIGhik@nduInDizdAmInyAnz@zwEl@zWRnomz-huznAmbRzarsogretD@tItwRizAstukipDEmclbIzi-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -natIgz@ktli-rItRndkAlIko-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -wErIzmYbrADRnW-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -InkwYRdS@gi-InDAmEtAlfcrAst-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -wErIzD@t-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -DAmEtAlfcrAst-IzInDAgretdomdk@vRn-DAlarjAstInclWRdAmInyAnz-rIplYdkAlIko-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -kAlIkohEzItetId-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -hWEvR-IfwilUkSarp-wimebiebAltudIskAvRwAnAvDizsikrAtwez-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -onoYmkwYtSUrhidIdAnt-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -D@tsfAni-rImarktbEtsiTctfAli-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -YdontbIliv@nuEnim@jIk-crSidh@vwRktItbIfcr-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -YdunatnokAnfEstS@gi-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -tru-AgridkAlIko-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -kAlIkowEntuDAbIgcG-AndpWndIdanItjAst@zrAgEdoyuzdtudu-bAtnowAn@nsRdDAsAmAnz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -h@vIGrItRndtuDArOAlk@vRn-kAlIko-fRstpWndIdDAgcGAndDEns@tInDATron-wErIGrAgIdozdIskardIdrubikrWn-AndholdIGInhIzh@ndDAsEptRwICrAgEdoh@dsocfAnTron@thIzhEd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -Am@nsEdtuDAyunAvRs-sR-YIgzIst-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -swEtkAvRdbrYAnzbadi-trIklIGIntuDAtYtlOnklcTD@twazDAonligarmAnthiwcr-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAkAtanhIzCEst-stIldrIpIGblAd-DAekAvhIzovRstrendYz-ivInDAscrIGRinARWndhImwIDATWzAndzAvspEktetRz-wRtrIvYAlYtIsnatwRTIGkIGAbWt-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -hIzInstAntAvp@nIkwazfalodbYAsmclSarp-blohYanhIzCEst-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -wAnmInAt-AvOsEd-AndDAtYmbAzRsWndAd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -AmInAtIznatAvErilarjmEZRAvtYm-AndhIzbadinidAdEvRifr@kSAnAvIt-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAbAzRzwR-trIgRdhIzmAsAlzIntukAmplitril@kseSAn-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -onlihIzhartAndlAGzwRkt-an@tAstrcGmEZRdret-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hiwazInrEvRi-slYdIGAlcGDAbcrdRzAvkanSAsnAs-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAkAntEstAntsInDAtwEntiznidAd-AndIstRbdrEst-DErfcr-nYtsInDAdcrmAtcrizwR@zkwYAt@zdET-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -partIkyAlRlisoanDIsl@stnYt-wEnonlituAvDAlItAlkyubIkAlzwRakyApYd-DATWzAndzAvADRzst@ndIGwIDdark-Emptidcrz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -DADRvOsn@ptwIDAharS-RjAnsi-klIrliyustukAm@nd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -YmhirbIkczDAm@tRIzAvAtmostImpcrtAns-Andbr@nd-IzDAwAnYmAstsi-nWst@ndAsYd-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAtwEntiz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -himAsth@vdrcnhIzgAn-bIkczDAIntrudRsEdkwIkli-pUtD@tAwe-yUrbiIGAful-Wt-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DErwazsYlAnsDEn-And-stIlwAndRIG-brYAnwazwAnsmcrAslip-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -tEnsEkAndz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -hi@sktDAh@ndlRhuwaznidIGhIzekIGmAsAlz-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -ArEdhErdmWntAnAvAm@n-wID@nApErAntliInIgzcstAbAlstcrAvEnRji-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DErkUdbilItAlartInDIs-l@stAndfYnAlrWndAvfEnsIG-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODOD Label String is: -jAstTrAst-AndpEri-AndvIktRituDAstrcGR-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -EvRim@nhuEntRdDAtwEntiz-h@dhIzontrenIGtrIks-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DErApIrdtubi@nImidiAtAsosieSAnwIDAdETtrcmA-@zIfDAtuwR-InEkstrIkAblilIGktIntuwAn-\n",
            "Pred String is,  DODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODODO Label String is: -DAstrEGkTD@tEnebAlzsAmwAnInAtr@nstuholdhIzbadistIf-AndAnsApcrtId-IksEpt@tupOnts-DAhEd-Andhilz-\n",
            "206.5625\n"
          ]
        }
      ],
      "source": [
        "# test code to check shapes\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model.eval()\n",
        "for i, data in enumerate(val_loader, 0):\n",
        "    x, y, lx, ly = data\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    h, lh = model(x, lx)\n",
        "    print(h.shape)\n",
        "    h_permuted = torch.permute(h, (1, 0, 2))\n",
        "    print(h_permuted.shape, y.shape)\n",
        "    loss = criterion(h_permuted, y, lh, ly)\n",
        "    print(loss)\n",
        "\n",
        "    print(calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd5aNaLVoR_g"
      },
      "source": [
        "# WandB\n",
        "\n",
        "You will need to fetch your api key from wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PiDduMaDIARE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4278671e-783a-477d-f49b-164dc8965694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaayush\u001b[0m (\u001b[33maaayush-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"7664f3b17a98ffe7c64b549e349123b61a9d3024\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4s52yBOvICPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9c586073-f840-4a64-ec14-4d704ac29e94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241028_064130-8t04u7p4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations/runs/8t04u7p4' target=\"_blank\">Better-Performance1-1</a></strong> to <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations' target=\"_blank\">https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations/runs/8t04u7p4' target=\"_blank\">https://wandb.ai/aaayush-carnegie-mellon-university/hw3p2-ablations/runs/8t04u7p4</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"Better-Performance1-1\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account\n",
        "    config = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "# Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ri87MAdhMUz5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16.\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    val_dist = vdist/len(val_loader)\n",
        "    return total_loss, val_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpYExu4vT4_g"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "husa5_EYMUz6"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tExvyl1BIdMC"
      },
      "outputs": [],
      "source": [
        "# This is for checkpointing, if you're doing it over multiple sessions\n",
        "\n",
        "last_epoch_completed = 0\n",
        "start = last_epoch_completed\n",
        "end = config[\"epochs\"]\n",
        "best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n",
        "epoch_model_path = \"/content/checkpoint/last_model.pth\"\n",
        "best_model_path = \"/content/checkpoint/best_model.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JR43E28rM9Ak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a7a4d63-29cb-47ca-b119-3caf8cadc69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 2.0181\t Learning Rate 0.0020000\n",
            "\tVal Dist 23.0059\t Val Loss 1.0384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 2/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.7505\t Learning Rate 0.0017086\n",
            "\tVal Dist 15.0506\t Val Loss 0.6881\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 3/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5316\t Learning Rate 0.0010050\n",
            "\tVal Dist 11.5287\t Val Loss 0.5306\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 4/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4157\t Learning Rate 0.0003014\n",
            "\tVal Dist 9.6537\t Val Loss 0.4506\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 5/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.5001\t Learning Rate 0.0020000\n",
            "\tVal Dist 11.4825\t Val Loss 0.5356\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 6/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3966\t Learning Rate 0.0019243\n",
            "\tVal Dist 9.3518\t Val Loss 0.4400\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 7/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3417\t Learning Rate 0.0017086\n",
            "\tVal Dist 8.5807\t Val Loss 0.4086\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 8/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2837\t Learning Rate 0.0013858\n",
            "\tVal Dist 7.6184\t Val Loss 0.3647\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 9/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2330\t Learning Rate 0.0010050\n",
            "\tVal Dist 7.2938\t Val Loss 0.3558\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 10/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1848\t Learning Rate 0.0006242\n",
            "\tVal Dist 6.7711\t Val Loss 0.3469\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 11/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1473\t Learning Rate 0.0003014\n",
            "\tVal Dist 6.5949\t Val Loss 0.3536\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 12/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1227\t Learning Rate 0.0000857\n",
            "\tVal Dist 6.4760\t Val Loss 0.3583\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 13/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3007\t Learning Rate 0.0020000\n",
            "\tVal Dist 8.2587\t Val Loss 0.4106\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 14/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2441\t Learning Rate 0.0019809\n",
            "\tVal Dist 7.8739\t Val Loss 0.3995\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 15/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2173\t Learning Rate 0.0019243\n",
            "\tVal Dist 7.2383\t Val Loss 0.3788\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 16/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1882\t Learning Rate 0.0018323\n",
            "\tVal Dist 7.3388\t Val Loss 0.3922\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 17/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1618\t Learning Rate 0.0017086\n",
            "\tVal Dist 6.9888\t Val Loss 0.3876\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 18/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1469\t Learning Rate 0.0015578\n",
            "\tVal Dist 6.6858\t Val Loss 0.3800\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 19/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1224\t Learning Rate 0.0013858\n",
            "\tVal Dist 6.6579\t Val Loss 0.3836\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 20/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1000\t Learning Rate 0.0011991\n",
            "\tVal Dist 6.5141\t Val Loss 0.4016\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 21/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0792\t Learning Rate 0.0010050\n",
            "\tVal Dist 6.3324\t Val Loss 0.4215\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 22/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0661\t Learning Rate 0.0008109\n",
            "\tVal Dist 6.3450\t Val Loss 0.4568\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 23/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0502\t Learning Rate 0.0006242\n",
            "\tVal Dist 6.2358\t Val Loss 0.4747\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 24/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0352\t Learning Rate 0.0004522\n",
            "\tVal Dist 6.0672\t Val Loss 0.5041\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 25/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0281\t Learning Rate 0.0003014\n",
            "\tVal Dist 6.1106\t Val Loss 0.5226\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 26/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0215\t Learning Rate 0.0001777\n",
            "\tVal Dist 5.9774\t Val Loss 0.5328\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 27/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0186\t Learning Rate 0.0000857\n",
            "\tVal Dist 5.9400\t Val Loss 0.5404\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 28/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0169\t Learning Rate 0.0000291\n",
            "\tVal Dist 5.9541\t Val Loss 0.5404\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 29/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2140\t Learning Rate 0.0020000\n",
            "\tVal Dist 7.7899\t Val Loss 0.4250\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 30/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1530\t Learning Rate 0.0019952\n",
            "\tVal Dist 6.7938\t Val Loss 0.3842\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 31/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1237\t Learning Rate 0.0019809\n",
            "\tVal Dist 6.9565\t Val Loss 0.4106\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 32/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1129\t Learning Rate 0.0019572\n",
            "\tVal Dist 6.7922\t Val Loss 0.4173\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 33/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0953\t Learning Rate 0.0019243\n",
            "\tVal Dist 6.6543\t Val Loss 0.4173\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 34/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0977\t Learning Rate 0.0018825\n",
            "\tVal Dist 6.6306\t Val Loss 0.4211\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 35/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0833\t Learning Rate 0.0018323\n",
            "\tVal Dist 6.6319\t Val Loss 0.4549\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 36/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0717\t Learning Rate 0.0017741\n",
            "\tVal Dist 6.7776\t Val Loss 0.4552\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 37/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0683\t Learning Rate 0.0017086\n",
            "\tVal Dist 6.3289\t Val Loss 0.4584\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 38/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0595\t Learning Rate 0.0016362\n",
            "\tVal Dist 6.3734\t Val Loss 0.4592\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 39/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0560\t Learning Rate 0.0015578\n",
            "\tVal Dist 6.4375\t Val Loss 0.4697\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 40/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0517\t Learning Rate 0.0014740\n",
            "\tVal Dist 6.3745\t Val Loss 0.4968\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 41/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0442\t Learning Rate 0.0013858\n",
            "\tVal Dist 6.2894\t Val Loss 0.4886\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 42/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0389\t Learning Rate 0.0012938\n",
            "\tVal Dist 6.2447\t Val Loss 0.5219\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 43/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0325\t Learning Rate 0.0011991\n",
            "\tVal Dist 6.2212\t Val Loss 0.5256\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 44/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0257\t Learning Rate 0.0011025\n",
            "\tVal Dist 6.3804\t Val Loss 0.5532\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 45/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0272\t Learning Rate 0.0010050\n",
            "\tVal Dist 6.1048\t Val Loss 0.5492\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 46/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0230\t Learning Rate 0.0009075\n",
            "\tVal Dist 6.1473\t Val Loss 0.5245\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 47/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0208\t Learning Rate 0.0008109\n",
            "\tVal Dist 6.0611\t Val Loss 0.5608\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 48/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  14%|█▍        | 64/446 [01:33<09:28,  1.49s/it, loss=0.0161, lr=0.000716]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1d36a4cdae8e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-abb89d234fb2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Another couple things you need for FP16.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is something added just for FP16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "#TODO: Please complete the training loop\n",
        "\n",
        "for epoch in range(0, config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "    train_loss = train_model(model, train_loader, criterion, optimizer)\n",
        "    valid_loss, valid_dist = validate_model(model, val_loader, decoder)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"\\tVal Dist {:.04f}\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
        "\n",
        "\n",
        "    wandb.log({\n",
        "        'train_loss': train_loss,\n",
        "        'valid_dist': valid_dist,\n",
        "        'valid_loss': valid_loss,\n",
        "        'lr'        : curr_lr\n",
        "    })\n",
        "\n",
        "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
        "    wandb.save(epoch_model_path)\n",
        "    print(\"Saved epoch model\")\n",
        "\n",
        "    if valid_dist <= best_lev_dist:\n",
        "        best_lev_dist = valid_dist\n",
        "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
        "        wandb.save(best_model_path)\n",
        "        print(\"Saved best model\")\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2H4EEj-sD32"
      },
      "source": [
        "# Generate Predictions and Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"/content/checkpoint/best_model.pth\")\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1-mxLd53GHL",
        "outputId": "f400966a-9363-4b42-f989-a54b9fdaf13a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2moYJhTWsOG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da10747-2105-4564-e0eb-92ba5b204d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/41 [00:01<00:44,  1.11s/it]\u001b[A\n",
            "  5%|▍         | 2/41 [00:02<00:46,  1.20s/it]\u001b[A\n",
            "  7%|▋         | 3/41 [00:03<00:50,  1.34s/it]\u001b[A\n",
            " 10%|▉         | 4/41 [00:04<00:45,  1.22s/it]\u001b[A\n",
            " 12%|█▏        | 5/41 [00:06<00:42,  1.19s/it]\u001b[A\n",
            " 15%|█▍        | 6/41 [00:06<00:38,  1.09s/it]\u001b[A\n",
            " 17%|█▋        | 7/41 [00:07<00:30,  1.10it/s]\u001b[A\n",
            " 20%|█▉        | 8/41 [00:08<00:34,  1.06s/it]\u001b[A\n",
            " 22%|██▏       | 9/41 [00:10<00:37,  1.16s/it]\u001b[A\n",
            " 24%|██▍       | 10/41 [00:11<00:37,  1.21s/it]\u001b[A\n",
            " 27%|██▋       | 11/41 [00:12<00:31,  1.04s/it]\u001b[A\n",
            " 29%|██▉       | 12/41 [00:13<00:29,  1.02s/it]\u001b[A\n",
            " 32%|███▏      | 13/41 [00:13<00:26,  1.07it/s]\u001b[A\n",
            " 34%|███▍      | 14/41 [00:15<00:27,  1.03s/it]\u001b[A\n",
            " 37%|███▋      | 15/41 [00:16<00:29,  1.12s/it]\u001b[A\n",
            " 39%|███▉      | 16/41 [00:17<00:29,  1.19s/it]\u001b[A\n",
            " 41%|████▏     | 17/41 [00:19<00:30,  1.28s/it]\u001b[A\n",
            " 44%|████▍     | 18/41 [00:20<00:29,  1.28s/it]\u001b[A\n",
            " 46%|████▋     | 19/41 [00:21<00:23,  1.05s/it]\u001b[A\n",
            " 49%|████▉     | 20/41 [00:22<00:25,  1.22s/it]\u001b[A\n",
            " 51%|█████     | 21/41 [00:24<00:25,  1.28s/it]\u001b[A\n",
            " 54%|█████▎    | 22/41 [00:25<00:24,  1.30s/it]\u001b[A\n",
            " 56%|█████▌    | 23/41 [00:26<00:23,  1.31s/it]\u001b[A\n",
            " 59%|█████▊    | 24/41 [00:27<00:18,  1.08s/it]\u001b[A\n",
            " 61%|██████    | 25/41 [00:28<00:18,  1.19s/it]\u001b[A\n",
            " 63%|██████▎   | 26/41 [00:29<00:17,  1.15s/it]\u001b[A\n",
            " 66%|██████▌   | 27/41 [00:30<00:14,  1.03s/it]\u001b[A\n",
            " 68%|██████▊   | 28/41 [00:31<00:12,  1.04it/s]\u001b[A\n",
            " 71%|███████   | 29/41 [00:32<00:12,  1.06s/it]\u001b[A\n",
            " 73%|███████▎  | 30/41 [00:33<00:10,  1.05it/s]\u001b[A\n",
            " 76%|███████▌  | 31/41 [00:34<00:10,  1.01s/it]\u001b[A\n",
            " 78%|███████▊  | 32/41 [00:35<00:10,  1.12s/it]\u001b[A\n",
            " 80%|████████  | 33/41 [00:37<00:09,  1.14s/it]\u001b[A\n",
            " 83%|████████▎ | 34/41 [00:38<00:07,  1.13s/it]\u001b[A\n",
            " 85%|████████▌ | 35/41 [00:39<00:06,  1.09s/it]\u001b[A\n",
            " 88%|████████▊ | 36/41 [00:40<00:06,  1.25s/it]\u001b[A\n",
            " 90%|█████████ | 37/41 [00:42<00:05,  1.29s/it]\u001b[A\n",
            " 93%|█████████▎| 38/41 [00:43<00:03,  1.17s/it]\u001b[A\n",
            " 95%|█████████▌| 39/41 [00:44<00:02,  1.12s/it]\u001b[A\n",
            " 98%|█████████▊| 40/41 [00:45<00:01,  1.11s/it]\u001b[A\n",
            "100%|██████████| 41/41 [00:46<00:00,  1.14s/it]\n"
          ]
        }
      ],
      "source": [
        "#TODO: Make predictions\n",
        "\n",
        "# Follow the steps below:\n",
        "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
        "# 2. Get prediction string by decoding the results of the beam decoder\n",
        "\n",
        "TEST_BEAM_WIDTH = 5\n",
        "\n",
        "test_decoder = CTCBeamDecoder(\n",
        "    labels=LABELS,\n",
        "    blank_id=0,\n",
        "    beam_width=TEST_BEAM_WIDTH,\n",
        "    num_processes=4,\n",
        "    log_probs_input=True\n",
        ")\n",
        "results = []\n",
        "\n",
        "model.eval()\n",
        "print(\"Testing\")\n",
        "for data in tqdm(test_loader):\n",
        "\n",
        "    x, lx   = data\n",
        "    x       = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h, lh = model(x, lx)\n",
        "\n",
        "    prediction_strings = decode_prediction(h, lh, test_decoder)\n",
        "    #TODO save the output in results array.\n",
        "\n",
        "    results.extend(prediction_strings)\n",
        "    del x, lx, h, lh\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"index\": range(len(results)), \"label\": results})\n",
        "\n",
        "# Save to the specified file path\n",
        "df.to_csv(\"/content/submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "AtXSpAZE7ohm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "m1sZmEIs4yIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6462a2b4-f64c-48de-dcbe-22dc51f2ee84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.5.8)\n",
            "100% 209k/209k [00:00<00:00, 351kB/s]\n",
            "Successfully submitted to Automatic Speech Recognition (ASR)"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c 11-785-hw3p2-f24 -f /content/submission.csv -m \"Better-Performance\"\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rd5aNaLVoR_g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10 (main, Feb 16 2023, 02:49:39) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}